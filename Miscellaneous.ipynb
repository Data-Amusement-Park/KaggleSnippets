{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory Usage Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import base\n",
    "from sklearn.model_selection import KFold\n",
    "class KFoldTargetEncoderTrain(base.BaseEstimator, base.TransformerMixin):\n",
    "\n",
    "    def __init__(self, colnames,targetName,n_fold=5,verbosity=True,discardOriginal_col=False):\n",
    "\n",
    "        self.colnames = colnames\n",
    "        self.targetName = targetName\n",
    "        self.n_fold = n_fold\n",
    "        self.verbosity = verbosity\n",
    "        self.discardOriginal_col = discardOriginal_col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform(self,X):\n",
    "\n",
    "        assert(type(self.targetName) == str)\n",
    "        assert(type(self.colnames) == str)\n",
    "        assert(self.colnames in X.columns)\n",
    "        assert(self.targetName in X.columns)\n",
    "\n",
    "        mean_of_target = X[self.targetName].mean()\n",
    "        kf = KFold(n_splits = self.n_fold, shuffle = False, random_state=2019)\n",
    "\n",
    "\n",
    "\n",
    "        col_mean_name = self.colnames + '_' + 'Kfold_Target_Enc'\n",
    "        X[col_mean_name] = np.nan\n",
    "\n",
    "        for tr_ind, val_ind in kf.split(X):\n",
    "            X_tr, X_val = X.iloc[tr_ind], X.iloc[val_ind]\n",
    "            X.loc[X.index[val_ind], col_mean_name] = X_val[self.colnames].map(X_tr.groupby(self.colnames)[self.targetName].mean())\n",
    "\n",
    "        X[col_mean_name].fillna(mean_of_target, inplace = True)\n",
    "\n",
    "        if self.verbosity:\n",
    "\n",
    "            encoded_feature = X[col_mean_name].values\n",
    "            print('Correlation between the new feature, {} and, {} is {}.'.format(col_mean_name,\n",
    "                                                                                      self.targetName,\n",
    "                                                                                      np.corrcoef(X[self.targetName].values, encoded_feature)[0][1]))\n",
    "        if self.discardOriginal_col:\n",
    "            X = X.drop(self.targetName, axis=1)\n",
    "            \n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFoldTargetEncoderTest(base.BaseEstimator, base.TransformerMixin):\n",
    "    def __init__(self,train,colNames,encodedName):\n",
    "        self.train = train\n",
    "        self.colNames = colNames\n",
    "        self.encodedName = encodedName\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        mean = self.train[[self.colNames,self.encodedName]].groupby(self.colNames).mean().reset_index()  \n",
    "        dd = {}\n",
    "        for index, row in mean.iterrows():\n",
    "            dd[row[self.colNames]] = row[self.encodedName]\n",
    "        X[self.encodedName] = X[self.colNames]\n",
    "        X = X.replace({self.encodedName: dd})\n",
    "        del dd\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targetc = KFoldTargetEncoderTrain('feature','target',n_fold=5)\n",
    "# X_train = targetc.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_targetc = KFoldTargetEncoderTest(X_train,'feature','feature' + '_Kfold_Target_Enc')\n",
    "# X_test = test_targetc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling latitudes and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, cos, sqrt, atan2, radians\n",
    "def haversine_distance(row):\n",
    "    c_lat,c_long = radians(52.5200), radians(13.4050)\n",
    "    R = 6373.0\n",
    "    long = radians(row['longitude'])\n",
    "    lat = radians(row['latitude'])\n",
    "    \n",
    "    dlon = long - c_long\n",
    "    dlat = lat - c_lat\n",
    "    a = sin(dlat / 2)**2 + cos(lat) * cos(c_lat) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    return R * c\n",
    "# df['distance_central'] = df.apply(haversine_distance,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download CSV without committing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "def create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n",
    "    csv = df.to_csv()\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "# create_download_link(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Hyper-Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    print(space)\n",
    "    clf = xgb.XGBRegressor(n_estimators =1000,colsample_bytree=space['colsample_bytree'],\n",
    "                           learning_rate = .3,\n",
    "                            max_depth = int(space['max_depth']),\n",
    "                            min_child_weight = space['min_child_weight'],\n",
    "                            subsample = space['subsample'],\n",
    "                           gamma = space['gamma'],\n",
    "                           reg_lambda = space['reg_lambda'],)\n",
    "\n",
    "    eval_set  = [( X, y), ( Xcv, ycv)] # training set - validation set\n",
    "\n",
    "    clf.fit(X, y,\n",
    "            eval_set=eval_set, eval_metric=\"rmse\",\n",
    "            early_stopping_rounds=10,verbose=False)\n",
    "\n",
    "    pred = clf.predict(Xcv)\n",
    "    mse_scr = mean_squared_error(ycv, pred)\n",
    "    print(\"SCORE:\", np.sqrt(mse_scr))\n",
    "    return {'loss':mse_scr}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "space ={'max_depth': hp.quniform(\"x_max_depth\", 4, 16, 1),\n",
    "        'min_child_weight': hp.quniform ('x_min_child', 1, 10, 1),\n",
    "        'subsample': hp.uniform ('x_subsample', 0.7, 1),\n",
    "        'gamma' : hp.uniform ('x_gamma', 0.1,0.5),\n",
    "        'colsample_bytree' : hp.uniform ('x_colsample_bytree', 0.7,1),\n",
    "        'reg_lambda' : hp.uniform ('x_reg_lambda', 0,1)\n",
    "    }\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100,\n",
    "            trials=trials)\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
