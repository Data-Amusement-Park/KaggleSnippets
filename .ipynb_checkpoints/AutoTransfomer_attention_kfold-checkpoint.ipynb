{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "z6TuFfcvZyno",
    "outputId": "4507381e-025f-43bb-bc89-be843a0fe84a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "LWFFLdrJZbNq",
    "outputId": "daf73e5a-6bed-4dcb-986e-6db132636487"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 368kB 2.8MB/s \n",
      "\u001b[K     |████████████████████████████████| 860kB 43.3MB/s \n",
      "\u001b[K     |████████████████████████████████| 675kB 46.3MB/s \n",
      "\u001b[K     |████████████████████████████████| 1.0MB 39.4MB/s \n",
      "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9W8iuy5iZbN0"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.cm as cm\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.metrics import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WJUOCfwJ7nG7"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bDcJAbWQmWmW"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# python RNG\n",
    "import random\n",
    "random.seed(seed)\n",
    "\n",
    "# pytorch RNGs\n",
    "import torch\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# numpy RNG\n",
    "import numpy as np\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pfkl3wOmaRkt"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/gdrive/My Drive/Definition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "17X4qG7RZbN-"
   },
   "outputs": [],
   "source": [
    "model_name=\"bert-base-uncased\"\n",
    "#model_name=\"roberta-base\"\n",
    "#model_name=\"xlnet-base-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "colab_type": "code",
    "id": "9Ad9AScmzi00",
    "outputId": "951ab562-6f6a-4c6b-d097-0ced7d0b2b39"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Psentence</th>\n",
       "      <th>Length</th>\n",
       "      <th>Dep1</th>\n",
       "      <th>Dep2</th>\n",
       "      <th>DepLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a pianist   is  a person who plays the piano</td>\n",
       "      <td>9</td>\n",
       "      <td>pianist is is person person plays plays piano</td>\n",
       "      <td>a pianist person a plays who piano the</td>\n",
       "      <td>nsubj ROOT ROOT attr attr relcl relcl dobj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>pingala has a sunlike nature and male energy</td>\n",
       "      <td>8</td>\n",
       "      <td>has has nature nature nature nature energy</td>\n",
       "      <td>pingala nature a sunlike and energy male</td>\n",
       "      <td>ROOT ROOT dobj dobj dobj dobj conj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  ...                                    DepLabel\n",
       "0      1  ...  nsubj ROOT ROOT attr attr relcl relcl dobj\n",
       "1      0  ...          ROOT ROOT dobj dobj dobj dobj conj\n",
       "\n",
       "[2 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.read_csv('data1.csv')\n",
    "merged.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Cggr4LVl1Le"
   },
   "outputs": [],
   "source": [
    "def seq_len(row):\n",
    "  return len(row['Psentence'].split())\n",
    "\n",
    "merged['Length'] = merged.apply(seq_len, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oj6xgU_Nl30d",
    "outputId": "87253fd4-6479-4397-c2d6-be24c4f65890"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4676, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = merged[merged['Length']>4]\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SLBkrbyeZbOp"
   },
   "outputs": [],
   "source": [
    "label_cols = list(set(merged['label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZI5qRserOi64"
   },
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8TBbnX8TZbOF",
    "outputId": "e7886ccc-6ff0-41cb-cf2b-81cde97a9c37"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231508/231508 [00:00<00:00, 419308.32B/s]\n"
     ]
    }
   ],
   "source": [
    " %tensorflow_version 1.x \n",
    "from transformers import BertTokenizer, GPT2Tokenizer, AutoTokenizer\n",
    "from transformers import BertConfig, BertForSequenceClassification, AutoModel, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, output_attentions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uqMNSbhMwCeA"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EJtATahguhJR",
    "outputId": "ec83b95a-ec20-4561-8251-8d92ef514313"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "MAX_LEN = 64\n",
    "X = [tokenizer.encode(x, add_special_tokens=True) for x in merged['Psentence']]\n",
    "X = pad_sequences(X, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g84o6yiZwfBr"
   },
   "outputs": [],
   "source": [
    "attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in X:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask)\n",
    "attention_masks = np.array(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oT3_hc6Sw0tw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NmQYwCcWxDQT"
   },
   "outputs": [],
   "source": [
    "y = np.array(merged['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qCrL_HHYxQwa"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vs29Zck60rpB",
    "outputId": "ff00f292-44d0-4b19-809d-95b5792a50e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9mqC5yTxyV3-"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import softmax\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    preds = softmax(preds)\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "\n",
    "def flat_f1(preds, labels):\n",
    "    preds = softmax(preds)\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, pred_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "EZww_KS_w93w",
    "outputId": "8d14d7c2-6df8-4853-b8d5-59a5a80e952e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------Fold # 0--------------------------------------------------------------------\n",
      "Epoch 0 | Train loss: 0.16608056772472055 | Validation Loss: 0.06789924862484137 \n",
      "Epoch 1 | Train loss: 0.11022858150924246 | Validation Loss: 0.0948705855756998 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       281\n",
      "           1       0.97      0.96      0.97       188\n",
      "\n",
      "    accuracy                           0.97       469\n",
      "   macro avg       0.97      0.97      0.97       469\n",
      "weighted avg       0.97      0.97      0.97       469\n",
      "\n",
      "--------------------------------------------------------------------------------Fold # 1--------------------------------------------------------------------\n",
      "Epoch 0 | Train loss: 0.1631806717310665 | Validation Loss: 0.08968668679396312 \n",
      "Epoch 1 | Train loss: 0.11086479149702372 | Validation Loss: 0.0916665264715751 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       281\n",
      "           1       0.96      0.98      0.97       188\n",
      "\n",
      "    accuracy                           0.98       469\n",
      "   macro avg       0.97      0.98      0.98       469\n",
      "weighted avg       0.98      0.98      0.98       469\n",
      "\n",
      "--------------------------------------------------------------------------------Fold # 2--------------------------------------------------------------------\n",
      "Epoch 0 | Train loss: 0.18062625373854782 | Validation Loss: 0.08908465926845868 \n",
      "Epoch 1 | Train loss: 0.11851130016712529 | Validation Loss: 0.06219957197705905 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       281\n",
      "           1       0.95      0.99      0.97       187\n",
      "\n",
      "    accuracy                           0.97       468\n",
      "   macro avg       0.97      0.98      0.97       468\n",
      "weighted avg       0.98      0.97      0.97       468\n",
      "\n",
      "--------------------------------------------------------------------------------Fold # 3--------------------------------------------------------------------\n",
      "Epoch 0 | Train loss: 0.19241523365913468 | Validation Loss: 0.05389601613084475 \n",
      "Epoch 1 | Train loss: 0.12268359292383221 | Validation Loss: 0.04752073039611181 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       281\n",
      "           1       0.96      1.00      0.98       187\n",
      "\n",
      "    accuracy                           0.99       468\n",
      "   macro avg       0.98      0.99      0.98       468\n",
      "weighted avg       0.99      0.99      0.99       468\n",
      "\n",
      "--------------------------------------------------------------------------------Fold # 4--------------------------------------------------------------------\n",
      "Epoch 0 | Train loss: 0.1617713585693502 | Validation Loss: 0.09146984182298183 \n",
      "Epoch 1 | Train loss: 0.10602349635111309 | Validation Loss: 0.06831331482777993 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       280\n",
      "           1       0.97      0.97      0.97       187\n",
      "\n",
      "    accuracy                           0.97       467\n",
      "   macro avg       0.97      0.97      0.97       467\n",
      "weighted avg       0.97      0.97      0.97       467\n",
      "\n",
      "--------------------------------------------------------------------------------Fold # 5--------------------------------------------------------------------\n",
      "Epoch 0 | Train loss: 0.1654135883842228 | Validation Loss: 0.1373450307796399 \n",
      "Epoch 1 | Train loss: 0.10891429128153532 | Validation Loss: 0.1311487233887116 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       280\n",
      "           1       0.95      0.96      0.95       187\n",
      "\n",
      "    accuracy                           0.96       467\n",
      "   macro avg       0.96      0.96      0.96       467\n",
      "weighted avg       0.96      0.96      0.96       467\n",
      "\n",
      "--------------------------------------------------------------------------------Fold # 6--------------------------------------------------------------------\n",
      "Epoch 0 | Train loss: 0.19580343508189826 | Validation Loss: 0.11232873561481635 \n",
      "Epoch 1 | Train loss: 0.12289629018667972 | Validation Loss: 0.09730999115854502 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       280\n",
      "           1       0.97      0.98      0.97       187\n",
      "\n",
      "    accuracy                           0.98       467\n",
      "   macro avg       0.98      0.98      0.98       467\n",
      "weighted avg       0.98      0.98      0.98       467\n",
      "\n",
      "--------------------------------------------------------------------------------Fold # 7--------------------------------------------------------------------\n",
      "Epoch 0 | Train loss: 0.18794614954315353 | Validation Loss: 0.06992352803548177 \n",
      "Epoch 1 | Train loss: 0.11644656921624008 | Validation Loss: 0.06259802115770678 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       280\n",
      "           1       0.96      0.97      0.97       187\n",
      "\n",
      "    accuracy                           0.97       467\n",
      "   macro avg       0.97      0.97      0.97       467\n",
      "weighted avg       0.97      0.97      0.97       467\n",
      "\n",
      "--------------------------------------------------------------------------------Fold # 8--------------------------------------------------------------------\n",
      "Epoch 0 | Train loss: 0.1640114399717387 | Validation Loss: 0.07479570383826892 \n",
      "Epoch 1 | Train loss: 0.11459914160447872 | Validation Loss: 0.05719721478720506 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       280\n",
      "           1       0.97      0.99      0.98       187\n",
      "\n",
      "    accuracy                           0.99       467\n",
      "   macro avg       0.98      0.99      0.98       467\n",
      "weighted avg       0.99      0.99      0.99       467\n",
      "\n",
      "--------------------------------------------------------------------------------Fold # 9--------------------------------------------------------------------\n",
      "Epoch 0 | Train loss: 0.1633050778711384 | Validation Loss: 0.09739237713317077 \n",
      "Epoch 1 | Train loss: 0.10604681785811078 | Validation Loss: 0.1115915318330129 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       280\n",
      "           1       0.94      0.97      0.96       187\n",
      "\n",
      "    accuracy                           0.96       467\n",
      "   macro avg       0.96      0.96      0.96       467\n",
      "weighted avg       0.96      0.96      0.96       467\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "auto_model = None\n",
    "\n",
    "kf = StratifiedKFold(10, shuffle=True, random_state=2018)\n",
    "for f,(tr, val) in enumerate(kf.split(X, y)):\n",
    "    print(f'--------------------------------------------------------------------------------Fold # {f}--------------------------------------------------------------------')\n",
    "\n",
    "    X_train, X_val = X[tr], X[val]\n",
    "    y_train, y_val = y[tr], y[val]\n",
    "    X_train_masks, X_val_masks = attention_masks[tr], attention_masks[val]\n",
    "                                         \n",
    "    # Convert all of our data into torch tensors, the required datatype for our model\n",
    "    X_train = torch.tensor(X_train)\n",
    "    X_val = torch.tensor(X_val)\n",
    "\n",
    "    y_train = torch.tensor(y_train)\n",
    "    y_val = torch.tensor(y_val)\n",
    "\n",
    "    X_train_masks = torch.tensor(X_train_masks)\n",
    "    X_val_masks = torch.tensor(X_val_masks)\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    # Create an iterator of our data with torch DataLoader \n",
    "    train_data = TensorDataset(X_train, X_train_masks, y_train)\n",
    "    train_sampler = SequentialSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "    validation_data = TensorDataset(X_val, X_val_masks, y_val)\n",
    "    validation_sampler = SequentialSampler(validation_data)\n",
    "    validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "    ## Model\n",
    "    del auto_model\n",
    "    auto_model = AutoModelForSequenceClassification.from_pretrained(model_name, output_attentions=True, num_labels= len(np.unique(y_train)))\n",
    "    auto_model.to(device)\n",
    "\n",
    "    # Optimizer\n",
    "    num_total_steps = 1000\n",
    "    num_warmup_steps = 100\n",
    "    lr = 2e-5\n",
    "    param_optimizer = list(auto_model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "        'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n",
    "    \n",
    "\n",
    "    auto_model.train()  \n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    n_epochs = 2\n",
    "\n",
    "    for epoch in (range(n_epochs)):  \n",
    "      # Training Loop\n",
    "      for step, batch in (enumerate(train_dataloader)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = auto_model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "\n",
    "        loss, logits = outputs[:2]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "          \n",
    "      auto_model.eval()\n",
    "      eval_loss, eval_accuracy = 0, 0\n",
    "      nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "      # Validation Loop\n",
    "      yt, yp = [], []\n",
    "      for batch in validation_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "          outputs = auto_model(b_input_ids, \n",
    "                              token_type_ids=None,\n",
    "                              attention_mask=b_input_mask,\n",
    "                              labels= b_labels)        \n",
    "          loss, logits = outputs[:2]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        \n",
    "        preds = softmax(logits)\n",
    "        pred_ids = np.argmax(preds, axis=1).flatten()\n",
    "\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        eval_loss += loss.item()\n",
    "        eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "        yt = yt + label_ids.tolist()\n",
    "        yp = yp + pred_ids.tolist()\n",
    "\n",
    "        nb_eval_steps +=1\n",
    "        \n",
    "      print(\"Epoch {} | Train loss: {} | Validation Loss: {} \".format(epoch,\n",
    "                                                                      tr_loss/nb_tr_steps,\n",
    "                                                                      eval_loss/nb_eval_steps, \n",
    "                                                                    ))\n",
    "    #if epoch == n_epochs:\n",
    "    print(classification_report(yt, yp))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_N3pLdh6qr6L"
   },
   "outputs": [],
   "source": [
    "torch.save(auto_model.state_dict(), 'models/bert_attn_97_10fold.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-KIjKKnqrBU"
   },
   "outputs": [],
   "source": [
    "auto_model.load_state_dict(torch.load('models/bert_attn_97_10fold.pth'))\n",
    "print(f'Done')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AutoTransfomer_attention_kfold.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
