{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "155a7a15ee2fcff1c1a2ea425a183d7359bd0365"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "54b9423886c0a4aaab02b90d0b87b14621a26d65"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "05956f14efe5883b4a07c76d09c5cef226401588"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 302)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "d27f39975f075d73109274d15515b59efe7b1956"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['target']==1.0].shape[0] / train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "29e8fc23a883e007bdd4feb114ce46406309364a"
   },
   "outputs": [],
   "source": [
    "# y = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "a25889ef30ca374c6d3a7f5abd1cc346fda72639"
   },
   "outputs": [],
   "source": [
    "train.drop(['id'],inplace=True,axis=1)\n",
    "test.drop(['id'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "98903057375b35753909b17423372a3604bc5a68"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_selection import RFECV,RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.24.0.5\n",
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"1.8.0_212\"; OpenJDK Runtime Environment (build 1.8.0_212-8u212-b03-2~deb9u1-b03); OpenJDK 64-Bit Server VM (build 25.212-b03, mixed mode)\n",
      "  Starting server from /opt/conda/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmp96ti0g6h\n",
      "  JVM stdout: /tmp/tmp96ti0g6h/h2o_unknownUser_started_from_python.out\n",
      "  JVM stderr: /tmp/tmp96ti0g6h/h2o_unknownUser_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.24.0.5</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>1 month and 6 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_unknownUser_48v7qp</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>14.22 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>2</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>2</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.6 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------\n",
       "H2O cluster uptime:         02 secs\n",
       "H2O cluster timezone:       Etc/UTC\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.24.0.5\n",
       "H2O cluster version age:    1 month and 6 days\n",
       "H2O cluster name:           H2O_from_python_unknownUser_48v7qp\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    14.22 Gb\n",
       "H2O cluster total cores:    2\n",
       "H2O cluster allowed cores:  2\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.6 final\n",
       "--------------------------  ---------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "print(h2o.__version__)\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "h2o.init(max_mem_size='16G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "train_D = h2o.H2OFrame(train)\n",
    "test_D = h2o.H2OFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = list(train.select_dtypes(['object']).columns)\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_D.columns\n",
    "y = 'target'\n",
    "# For binary classification, response should be a factor\n",
    "train_D[y] = train_D[y].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "aml = H2OAutoML(max_models=50, seed=25, max_runtime_secs=60*10)\n",
    "aml.train(x=x, y=y, training_frame=train_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                           </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190725_053020_model_10     </td><td style=\"text-align: right;\">0.733403</td><td style=\"text-align: right;\"> 0.575085</td><td style=\"text-align: right;\">              0.413194</td><td style=\"text-align: right;\">0.444003</td><td style=\"text-align: right;\">0.197139</td></tr>\n",
       "<tr><td>GLM_grid_1_AutoML_20190725_053020_model_1          </td><td style=\"text-align: right;\">0.726389</td><td style=\"text-align: right;\"> 0.576526</td><td style=\"text-align: right;\">              0.427431</td><td style=\"text-align: right;\">0.445664</td><td style=\"text-align: right;\">0.198617</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190725_053020_model_9      </td><td style=\"text-align: right;\">0.715694</td><td style=\"text-align: right;\"> 0.58059 </td><td style=\"text-align: right;\">              0.345139</td><td style=\"text-align: right;\">0.444336</td><td style=\"text-align: right;\">0.197434</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20190725_053020</td><td style=\"text-align: right;\">0.713264</td><td style=\"text-align: right;\"> 0.59449 </td><td style=\"text-align: right;\">              0.421875</td><td style=\"text-align: right;\">0.452472</td><td style=\"text-align: right;\">0.204731</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190725_053020_model_2 </td><td style=\"text-align: right;\">0.706285</td><td style=\"text-align: right;\"> 4.29487 </td><td style=\"text-align: right;\">              0.392361</td><td style=\"text-align: right;\">0.53879 </td><td style=\"text-align: right;\">0.290294</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190725_053020_model_3      </td><td style=\"text-align: right;\">0.705625</td><td style=\"text-align: right;\"> 0.587155</td><td style=\"text-align: right;\">              0.364583</td><td style=\"text-align: right;\">0.447035</td><td style=\"text-align: right;\">0.19984 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190725_053020_model_8      </td><td style=\"text-align: right;\">0.705   </td><td style=\"text-align: right;\"> 0.58749 </td><td style=\"text-align: right;\">              0.332292</td><td style=\"text-align: right;\">0.448142</td><td style=\"text-align: right;\">0.200831</td></tr>\n",
       "<tr><td>XGBoost_1_AutoML_20190725_053020                   </td><td style=\"text-align: right;\">0.7025  </td><td style=\"text-align: right;\"> 0.590869</td><td style=\"text-align: right;\">              0.417361</td><td style=\"text-align: right;\">0.449443</td><td style=\"text-align: right;\">0.201999</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20190725_053020   </td><td style=\"text-align: right;\">0.700417</td><td style=\"text-align: right;\"> 0.601023</td><td style=\"text-align: right;\">              0.415625</td><td style=\"text-align: right;\">0.454062</td><td style=\"text-align: right;\">0.206172</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190725_053020_model_6          </td><td style=\"text-align: right;\">0.691458</td><td style=\"text-align: right;\"> 0.776322</td><td style=\"text-align: right;\">              0.472222</td><td style=\"text-align: right;\">0.489209</td><td style=\"text-align: right;\">0.239325</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190725_053020_model_12     </td><td style=\"text-align: right;\">0.691458</td><td style=\"text-align: right;\"> 0.606952</td><td style=\"text-align: right;\">              0.377778</td><td style=\"text-align: right;\">0.456811</td><td style=\"text-align: right;\">0.208677</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190725_053020_model_1 </td><td style=\"text-align: right;\">0.690521</td><td style=\"text-align: right;\"> 5.25093 </td><td style=\"text-align: right;\">              0.325694</td><td style=\"text-align: right;\">0.525185</td><td style=\"text-align: right;\">0.275819</td></tr>\n",
       "<tr><td>GBM_3_AutoML_20190725_053020                       </td><td style=\"text-align: right;\">0.689722</td><td style=\"text-align: right;\"> 0.616357</td><td style=\"text-align: right;\">              0.405208</td><td style=\"text-align: right;\">0.459844</td><td style=\"text-align: right;\">0.211457</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190725_053020_model_3          </td><td style=\"text-align: right;\">0.689444</td><td style=\"text-align: right;\"> 0.639623</td><td style=\"text-align: right;\">              0.458681</td><td style=\"text-align: right;\">0.465548</td><td style=\"text-align: right;\">0.216735</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190725_053020_model_4          </td><td style=\"text-align: right;\">0.686944</td><td style=\"text-align: right;\"> 0.605888</td><td style=\"text-align: right;\">              0.442014</td><td style=\"text-align: right;\">0.454841</td><td style=\"text-align: right;\">0.206881</td></tr>\n",
       "<tr><td>GBM_2_AutoML_20190725_053020                       </td><td style=\"text-align: right;\">0.685833</td><td style=\"text-align: right;\"> 0.618502</td><td style=\"text-align: right;\">              0.419444</td><td style=\"text-align: right;\">0.460468</td><td style=\"text-align: right;\">0.212031</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190725_053020_model_7          </td><td style=\"text-align: right;\">0.684167</td><td style=\"text-align: right;\"> 1.03186 </td><td style=\"text-align: right;\">              0.406944</td><td style=\"text-align: right;\">0.522091</td><td style=\"text-align: right;\">0.272579</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190725_053020_model_3 </td><td style=\"text-align: right;\">0.680382</td><td style=\"text-align: right;\"> 4.27186 </td><td style=\"text-align: right;\">              0.390625</td><td style=\"text-align: right;\">0.561603</td><td style=\"text-align: right;\">0.315398</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190725_053020_model_7 </td><td style=\"text-align: right;\">0.679444</td><td style=\"text-align: right;\"> 2.18418 </td><td style=\"text-align: right;\">              0.429861</td><td style=\"text-align: right;\">0.542085</td><td style=\"text-align: right;\">0.293857</td></tr>\n",
       "<tr><td>GBM_4_AutoML_20190725_053020                       </td><td style=\"text-align: right;\">0.677431</td><td style=\"text-align: right;\"> 0.624303</td><td style=\"text-align: right;\">              0.408333</td><td style=\"text-align: right;\">0.46319 </td><td style=\"text-align: right;\">0.214545</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190725_053020_model_4 </td><td style=\"text-align: right;\">0.677153</td><td style=\"text-align: right;\"> 1.96654 </td><td style=\"text-align: right;\">              0.450694</td><td style=\"text-align: right;\">0.539677</td><td style=\"text-align: right;\">0.291251</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190725_053020_model_1      </td><td style=\"text-align: right;\">0.676389</td><td style=\"text-align: right;\"> 0.645138</td><td style=\"text-align: right;\">              0.451389</td><td style=\"text-align: right;\">0.475711</td><td style=\"text-align: right;\">0.226301</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190725_053020_model_6 </td><td style=\"text-align: right;\">0.672604</td><td style=\"text-align: right;\"> 4.4735  </td><td style=\"text-align: right;\">              0.456944</td><td style=\"text-align: right;\">0.570505</td><td style=\"text-align: right;\">0.325475</td></tr>\n",
       "<tr><td>GBM_5_AutoML_20190725_053020                       </td><td style=\"text-align: right;\">0.671944</td><td style=\"text-align: right;\"> 0.617158</td><td style=\"text-align: right;\">              0.469792</td><td style=\"text-align: right;\">0.461509</td><td style=\"text-align: right;\">0.21299 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190725_053020_model_4      </td><td style=\"text-align: right;\">0.671771</td><td style=\"text-align: right;\"> 0.62841 </td><td style=\"text-align: right;\">              0.416319</td><td style=\"text-align: right;\">0.467676</td><td style=\"text-align: right;\">0.21872 </td></tr>\n",
       "<tr><td>XGBoost_3_AutoML_20190725_053020                   </td><td style=\"text-align: right;\">0.667986</td><td style=\"text-align: right;\"> 0.614173</td><td style=\"text-align: right;\">              0.368056</td><td style=\"text-align: right;\">0.46076 </td><td style=\"text-align: right;\">0.2123  </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190725_053020_model_11     </td><td style=\"text-align: right;\">0.659757</td><td style=\"text-align: right;\"> 0.627625</td><td style=\"text-align: right;\">              0.45625 </td><td style=\"text-align: right;\">0.467295</td><td style=\"text-align: right;\">0.218365</td></tr>\n",
       "<tr><td>XGBoost_2_AutoML_20190725_053020                   </td><td style=\"text-align: right;\">0.657014</td><td style=\"text-align: right;\"> 0.622644</td><td style=\"text-align: right;\">              0.409028</td><td style=\"text-align: right;\">0.464564</td><td style=\"text-align: right;\">0.215819</td></tr>\n",
       "<tr><td>GBM_1_AutoML_20190725_053020                       </td><td style=\"text-align: right;\">0.646597</td><td style=\"text-align: right;\"> 0.710378</td><td style=\"text-align: right;\">              0.472917</td><td style=\"text-align: right;\">0.485587</td><td style=\"text-align: right;\">0.235795</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190725_053020_model_8          </td><td style=\"text-align: right;\">0.646424</td><td style=\"text-align: right;\"> 0.637345</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.47215 </td><td style=\"text-align: right;\">0.222926</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190725_053020_model_5 </td><td style=\"text-align: right;\">0.641319</td><td style=\"text-align: right;\"> 1.35274 </td><td style=\"text-align: right;\">              0.429861</td><td style=\"text-align: right;\">0.532484</td><td style=\"text-align: right;\">0.283539</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190725_053020_model_1          </td><td style=\"text-align: right;\">0.637778</td><td style=\"text-align: right;\"> 1.00449 </td><td style=\"text-align: right;\">              0.453125</td><td style=\"text-align: right;\">0.523808</td><td style=\"text-align: right;\">0.274375</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190725_053020_model_6      </td><td style=\"text-align: right;\">0.636042</td><td style=\"text-align: right;\"> 0.663765</td><td style=\"text-align: right;\">              0.442708</td><td style=\"text-align: right;\">0.47846 </td><td style=\"text-align: right;\">0.228924</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190725_053020_model_5          </td><td style=\"text-align: right;\">0.616111</td><td style=\"text-align: right;\"> 0.639463</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.473174</td><td style=\"text-align: right;\">0.223894</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190725_053020_model_9          </td><td style=\"text-align: right;\">0.615833</td><td style=\"text-align: right;\"> 0.641763</td><td style=\"text-align: right;\">              0.410417</td><td style=\"text-align: right;\">0.474196</td><td style=\"text-align: right;\">0.224862</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190725_053020_model_7      </td><td style=\"text-align: right;\">0.614375</td><td style=\"text-align: right;\"> 0.647424</td><td style=\"text-align: right;\">              0.483333</td><td style=\"text-align: right;\">0.477014</td><td style=\"text-align: right;\">0.227543</td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_20190725_053020              </td><td style=\"text-align: right;\">0.585347</td><td style=\"text-align: right;\"> 1.15385 </td><td style=\"text-align: right;\">              0.488889</td><td style=\"text-align: right;\">0.561618</td><td style=\"text-align: right;\">0.315415</td></tr>\n",
       "<tr><td>XRT_1_AutoML_20190725_053020                       </td><td style=\"text-align: right;\">0.575069</td><td style=\"text-align: right;\"> 0.785833</td><td style=\"text-align: right;\">              0.494444</td><td style=\"text-align: right;\">0.482628</td><td style=\"text-align: right;\">0.232929</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190725_053020_model_8 </td><td style=\"text-align: right;\">0.560278</td><td style=\"text-align: right;\"> 1.82083 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.570459</td><td style=\"text-align: right;\">0.325423</td></tr>\n",
       "<tr><td>DRF_1_AutoML_20190725_053020                       </td><td style=\"text-align: right;\">0.549375</td><td style=\"text-align: right;\"> 0.678053</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.489275</td><td style=\"text-align: right;\">0.23939 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190725_053020_model_5      </td><td style=\"text-align: right;\">0.51934 </td><td style=\"text-align: right;\"> 0.663419</td><td style=\"text-align: right;\">              0.476042</td><td style=\"text-align: right;\">0.484996</td><td style=\"text-align: right;\">0.235222</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190725_053020_model_2          </td><td style=\"text-align: right;\">0.460139</td><td style=\"text-align: right;\"> 0.657784</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.482097</td><td style=\"text-align: right;\">0.232417</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190725_053020_model_2      </td><td style=\"text-align: right;\">0.413194</td><td style=\"text-align: right;\"> 0.660151</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.483301</td><td style=\"text-align: right;\">0.23358 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = aml.leaderboard\n",
    "lb.head(rows=lb.nrows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OXGBoostEstimator :  XGBoost\n",
      "Model Key:  XGBoost_grid_1_AutoML_20190725_053020_model_10\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: xgboost\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.02670557027462496\n",
      "RMSE: 0.1634183902583334\n",
      "LogLoss: 0.16652576342191194\n",
      "Mean Per-Class Error: 0.0\n",
      "AUC: 1.0\n",
      "pr_auc: 0.9937499999999999\n",
      "Gini: 1.0\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.7300984263420105: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>90.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/90.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.0</td>\n",
       "<td>160.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/160.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>90.0</td>\n",
       "<td>160.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/250.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "0      90   0    0        (0.0/90.0)\n",
       "1      0    160  0        (0.0/160.0)\n",
       "Total  90   160  0        (0.0/250.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.7300984</td>\n",
       "<td>1.0</td>\n",
       "<td>159.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.7300984</td>\n",
       "<td>1.0</td>\n",
       "<td>159.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7300984</td>\n",
       "<td>1.0</td>\n",
       "<td>159.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.7300984</td>\n",
       "<td>1.0</td>\n",
       "<td>159.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9558320</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.7300984</td>\n",
       "<td>1.0</td>\n",
       "<td>159.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9558320</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.7300984</td>\n",
       "<td>1.0</td>\n",
       "<td>159.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.7300984</td>\n",
       "<td>1.0</td>\n",
       "<td>159.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.7300984</td>\n",
       "<td>1.0</td>\n",
       "<td>159.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value    idx\n",
       "---------------------------  -----------  -------  -----\n",
       "max f1                       0.730098     1        159\n",
       "max f2                       0.730098     1        159\n",
       "max f0point5                 0.730098     1        159\n",
       "max accuracy                 0.730098     1        159\n",
       "max precision                0.955832     1        0\n",
       "max recall                   0.730098     1        159\n",
       "max specificity              0.955832     1        0\n",
       "max absolute_mcc             0.730098     1        159\n",
       "max min_per_class_accuracy   0.730098     1        159\n",
       "max mean_per_class_accuracy  0.730098     1        159"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 64.00 %, avg score: 63.49 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.012</td>\n",
       "<td>0.9514296</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9537740</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9537740</td>\n",
       "<td>0.01875</td>\n",
       "<td>0.01875</td>\n",
       "<td>56.25</td>\n",
       "<td>56.25</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.02</td>\n",
       "<td>0.9390598</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9449219</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9502332</td>\n",
       "<td>0.0125</td>\n",
       "<td>0.03125</td>\n",
       "<td>56.25</td>\n",
       "<td>56.25</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.032</td>\n",
       "<td>0.9341254</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9377736</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9455608</td>\n",
       "<td>0.01875</td>\n",
       "<td>0.05</td>\n",
       "<td>56.25</td>\n",
       "<td>56.25</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.04</td>\n",
       "<td>0.9321712</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9324644</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9429415</td>\n",
       "<td>0.0125</td>\n",
       "<td>0.0625</td>\n",
       "<td>56.25</td>\n",
       "<td>56.25</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.052</td>\n",
       "<td>0.9317092</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9320440</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9404267</td>\n",
       "<td>0.01875</td>\n",
       "<td>0.08125</td>\n",
       "<td>56.25</td>\n",
       "<td>56.25</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.9196121</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9245933</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9328267</td>\n",
       "<td>0.075</td>\n",
       "<td>0.15625</td>\n",
       "<td>56.25</td>\n",
       "<td>56.25</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.152</td>\n",
       "<td>0.9124347</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9161748</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9271300</td>\n",
       "<td>0.08125</td>\n",
       "<td>0.2375</td>\n",
       "<td>56.25</td>\n",
       "<td>56.25</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.9040492</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9084734</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9226524</td>\n",
       "<td>0.075</td>\n",
       "<td>0.3125</td>\n",
       "<td>56.25</td>\n",
       "<td>56.25</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.8853474</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8955751</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9136267</td>\n",
       "<td>0.15625</td>\n",
       "<td>0.46875</td>\n",
       "<td>56.25</td>\n",
       "<td>56.25</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.8673383</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8755724</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9041131</td>\n",
       "<td>0.15625</td>\n",
       "<td>0.625</td>\n",
       "<td>56.25</td>\n",
       "<td>56.25</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.8480713</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8574645</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8947834</td>\n",
       "<td>0.15625</td>\n",
       "<td>0.78125</td>\n",
       "<td>56.25</td>\n",
       "<td>56.25</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.8047110</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8344924</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8847349</td>\n",
       "<td>0.15625</td>\n",
       "<td>0.9375</td>\n",
       "<td>56.25</td>\n",
       "<td>56.25</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.2657058</td>\n",
       "<td>0.625</td>\n",
       "<td>1.4285714</td>\n",
       "<td>0.4</td>\n",
       "<td>0.4942095</td>\n",
       "<td>0.9142857</td>\n",
       "<td>0.8289455</td>\n",
       "<td>0.0625</td>\n",
       "<td>1.0</td>\n",
       "<td>-37.5</td>\n",
       "<td>42.8571429</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.1993634</td>\n",
       "<td>0.0</td>\n",
       "<td>1.25</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2254169</td>\n",
       "<td>0.8</td>\n",
       "<td>0.7535045</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.1606414</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1111111</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1809483</td>\n",
       "<td>0.7111111</td>\n",
       "<td>0.6898871</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1111111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0866511</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1395958</td>\n",
       "<td>0.64</td>\n",
       "<td>0.6348580</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift    cumulative_lift    response_rate    score     cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain    cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ------  -----------------  ---------------  --------  --------------------------  ------------------  --------------  -------------------------  ------  -----------------\n",
       "    1        0.012                       0.95143            1.5625  1.5625             1                0.953774  1                           0.953774            0.01875         0.01875                    56.25   56.25\n",
       "    2        0.02                        0.93906            1.5625  1.5625             1                0.944922  1                           0.950233            0.0125          0.03125                    56.25   56.25\n",
       "    3        0.032                       0.934125           1.5625  1.5625             1                0.937774  1                           0.945561            0.01875         0.05                       56.25   56.25\n",
       "    4        0.04                        0.932171           1.5625  1.5625             1                0.932464  1                           0.942942            0.0125          0.0625                     56.25   56.25\n",
       "    5        0.052                       0.931709           1.5625  1.5625             1                0.932044  1                           0.940427            0.01875         0.08125                    56.25   56.25\n",
       "    6        0.1                         0.919612           1.5625  1.5625             1                0.924593  1                           0.932827            0.075           0.15625                    56.25   56.25\n",
       "    7        0.152                       0.912435           1.5625  1.5625             1                0.916175  1                           0.92713             0.08125         0.2375                     56.25   56.25\n",
       "    8        0.2                         0.904049           1.5625  1.5625             1                0.908473  1                           0.922652            0.075           0.3125                     56.25   56.25\n",
       "    9        0.3                         0.885347           1.5625  1.5625             1                0.895575  1                           0.913627            0.15625         0.46875                    56.25   56.25\n",
       "    10       0.4                         0.867338           1.5625  1.5625             1                0.875572  1                           0.904113            0.15625         0.625                      56.25   56.25\n",
       "    11       0.5                         0.848071           1.5625  1.5625             1                0.857465  1                           0.894783            0.15625         0.78125                    56.25   56.25\n",
       "    12       0.6                         0.804711           1.5625  1.5625             1                0.834492  1                           0.884735            0.15625         0.9375                     56.25   56.25\n",
       "    13       0.7                         0.265706           0.625   1.42857            0.4              0.494209  0.914286                    0.828946            0.0625          1                          -37.5   42.8571\n",
       "    14       0.8                         0.199363           0       1.25               0                0.225417  0.8                         0.753504            0               1                          -100    25\n",
       "    15       0.9                         0.160641           0       1.11111            0                0.180948  0.711111                    0.689887            0               1                          -100    11.1111\n",
       "    16       1                           0.0866511          0       1                  0                0.139596  0.64                        0.634858            0               1                          -100    0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: xgboost\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.1971389742333621\n",
      "RMSE: 0.4440033493492612\n",
      "LogLoss: 0.5750851173686681\n",
      "Mean Per-Class Error: 0.3222222222222222\n",
      "AUC: 0.7334027777777777\n",
      "pr_auc: 0.830401990545337\n",
      "Gini: 0.4668055555555555\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.38387003540992737: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>19.0</td>\n",
       "<td>71.0</td>\n",
       "<td>0.7889</td>\n",
       "<td> (71.0/90.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>6.0</td>\n",
       "<td>154.0</td>\n",
       "<td>0.0375</td>\n",
       "<td> (6.0/160.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>25.0</td>\n",
       "<td>225.0</td>\n",
       "<td>0.308</td>\n",
       "<td> (77.0/250.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      19   71   0.7889   (71.0/90.0)\n",
       "1      6    154  0.0375   (6.0/160.0)\n",
       "Total  25   225  0.308    (77.0/250.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3838700</td>\n",
       "<td>0.8</td>\n",
       "<td>224.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.2136558</td>\n",
       "<td>0.9009009</td>\n",
       "<td>247.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5809521</td>\n",
       "<td>0.7696759</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5809521</td>\n",
       "<td>0.72</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9382890</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.2136558</td>\n",
       "<td>1.0</td>\n",
       "<td>247.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9382890</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.5809521</td>\n",
       "<td>0.3716758</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.6860646</td>\n",
       "<td>0.6555556</td>\n",
       "<td>135.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.6056440</td>\n",
       "<td>0.6777778</td>\n",
       "<td>167.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.38387      0.8       224\n",
       "max f2                       0.213656     0.900901  247\n",
       "max f0point5                 0.580952     0.769676  175\n",
       "max accuracy                 0.580952     0.72      175\n",
       "max precision                0.938289     1         0\n",
       "max recall                   0.213656     1         247\n",
       "max specificity              0.938289     1         0\n",
       "max absolute_mcc             0.580952     0.371676  175\n",
       "max min_per_class_accuracy   0.686065     0.655556  135\n",
       "max mean_per_class_accuracy  0.605644     0.677778  167"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 64.00 %, avg score: 66.33 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.012</td>\n",
       "<td>0.9237880</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9322035</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9322035</td>\n",
       "<td>0.01875</td>\n",
       "<td>0.01875</td>\n",
       "<td>56.25</td>\n",
       "<td>56.25</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.02</td>\n",
       "<td>0.9214962</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9224392</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9282978</td>\n",
       "<td>0.0125</td>\n",
       "<td>0.03125</td>\n",
       "<td>56.25</td>\n",
       "<td>56.25</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.032</td>\n",
       "<td>0.9071620</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9159970</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9236850</td>\n",
       "<td>0.01875</td>\n",
       "<td>0.05</td>\n",
       "<td>56.25</td>\n",
       "<td>56.25</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.04</td>\n",
       "<td>0.9033309</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9054477</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9200375</td>\n",
       "<td>0.0125</td>\n",
       "<td>0.0625</td>\n",
       "<td>56.25</td>\n",
       "<td>56.25</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.052</td>\n",
       "<td>0.8941236</td>\n",
       "<td>1.0416667</td>\n",
       "<td>1.4423077</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.8976548</td>\n",
       "<td>0.9230769</td>\n",
       "<td>0.9148723</td>\n",
       "<td>0.0125</td>\n",
       "<td>0.075</td>\n",
       "<td>4.1666667</td>\n",
       "<td>44.2307692</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.8611287</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8738879</td>\n",
       "<td>0.96</td>\n",
       "<td>0.8951998</td>\n",
       "<td>0.075</td>\n",
       "<td>0.15</td>\n",
       "<td>56.25</td>\n",
       "<td>50.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.152</td>\n",
       "<td>0.8461954</td>\n",
       "<td>1.4423077</td>\n",
       "<td>1.4802632</td>\n",
       "<td>0.9230769</td>\n",
       "<td>0.8520490</td>\n",
       "<td>0.9473684</td>\n",
       "<td>0.8804377</td>\n",
       "<td>0.075</td>\n",
       "<td>0.225</td>\n",
       "<td>44.2307692</td>\n",
       "<td>48.0263158</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.8339423</td>\n",
       "<td>1.4322917</td>\n",
       "<td>1.4687500</td>\n",
       "<td>0.9166667</td>\n",
       "<td>0.8387385</td>\n",
       "<td>0.94</td>\n",
       "<td>0.8704299</td>\n",
       "<td>0.06875</td>\n",
       "<td>0.29375</td>\n",
       "<td>43.2291667</td>\n",
       "<td>46.8750000</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.7830305</td>\n",
       "<td>1.3125</td>\n",
       "<td>1.4166667</td>\n",
       "<td>0.84</td>\n",
       "<td>0.8104523</td>\n",
       "<td>0.9066667</td>\n",
       "<td>0.8504373</td>\n",
       "<td>0.13125</td>\n",
       "<td>0.425</td>\n",
       "<td>31.25</td>\n",
       "<td>41.6666667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.7448896</td>\n",
       "<td>0.625</td>\n",
       "<td>1.21875</td>\n",
       "<td>0.4</td>\n",
       "<td>0.7627006</td>\n",
       "<td>0.78</td>\n",
       "<td>0.8285031</td>\n",
       "<td>0.0625</td>\n",
       "<td>0.4875</td>\n",
       "<td>-37.5</td>\n",
       "<td>21.875</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.7070857</td>\n",
       "<td>1.25</td>\n",
       "<td>1.225</td>\n",
       "<td>0.8</td>\n",
       "<td>0.7276273</td>\n",
       "<td>0.784</td>\n",
       "<td>0.8083280</td>\n",
       "<td>0.125</td>\n",
       "<td>0.6125</td>\n",
       "<td>25.0</td>\n",
       "<td>22.5000000</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.6537915</td>\n",
       "<td>1.0</td>\n",
       "<td>1.1875</td>\n",
       "<td>0.64</td>\n",
       "<td>0.6795115</td>\n",
       "<td>0.76</td>\n",
       "<td>0.7868586</td>\n",
       "<td>0.1</td>\n",
       "<td>0.7125</td>\n",
       "<td>0.0</td>\n",
       "<td>18.75</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.5829210</td>\n",
       "<td>1.125</td>\n",
       "<td>1.1785714</td>\n",
       "<td>0.72</td>\n",
       "<td>0.6176361</td>\n",
       "<td>0.7542857</td>\n",
       "<td>0.7626839</td>\n",
       "<td>0.1125</td>\n",
       "<td>0.825</td>\n",
       "<td>12.5</td>\n",
       "<td>17.8571429</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.5129873</td>\n",
       "<td>0.5</td>\n",
       "<td>1.09375</td>\n",
       "<td>0.32</td>\n",
       "<td>0.5495823</td>\n",
       "<td>0.7</td>\n",
       "<td>0.7360462</td>\n",
       "<td>0.05</td>\n",
       "<td>0.875</td>\n",
       "<td>-50.0</td>\n",
       "<td>9.375</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.3837755</td>\n",
       "<td>0.8750000</td>\n",
       "<td>1.0694444</td>\n",
       "<td>0.56</td>\n",
       "<td>0.4464045</td>\n",
       "<td>0.6844444</td>\n",
       "<td>0.7038638</td>\n",
       "<td>0.0875</td>\n",
       "<td>0.9625</td>\n",
       "<td>-12.5000000</td>\n",
       "<td>6.9444444</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1801038</td>\n",
       "<td>0.375</td>\n",
       "<td>1.0</td>\n",
       "<td>0.24</td>\n",
       "<td>0.2977606</td>\n",
       "<td>0.64</td>\n",
       "<td>0.6632535</td>\n",
       "<td>0.0375</td>\n",
       "<td>1.0</td>\n",
       "<td>-62.5</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score     cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  --------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.012                       0.923788           1.5625   1.5625             1                0.932204  1                           0.932204            0.01875         0.01875                    56.25    56.25\n",
       "    2        0.02                        0.921496           1.5625   1.5625             1                0.922439  1                           0.928298            0.0125          0.03125                    56.25    56.25\n",
       "    3        0.032                       0.907162           1.5625   1.5625             1                0.915997  1                           0.923685            0.01875         0.05                       56.25    56.25\n",
       "    4        0.04                        0.903331           1.5625   1.5625             1                0.905448  1                           0.920038            0.0125          0.0625                     56.25    56.25\n",
       "    5        0.052                       0.894124           1.04167  1.44231            0.666667         0.897655  0.923077                    0.914872            0.0125          0.075                      4.16667  44.2308\n",
       "    6        0.1                         0.861129           1.5625   1.5                1                0.873888  0.96                        0.8952              0.075           0.15                       56.25    50\n",
       "    7        0.152                       0.846195           1.44231  1.48026            0.923077         0.852049  0.947368                    0.880438            0.075           0.225                      44.2308  48.0263\n",
       "    8        0.2                         0.833942           1.43229  1.46875            0.916667         0.838738  0.94                        0.87043             0.06875         0.29375                    43.2292  46.875\n",
       "    9        0.3                         0.783031           1.3125   1.41667            0.84             0.810452  0.906667                    0.850437            0.13125         0.425                      31.25    41.6667\n",
       "    10       0.4                         0.74489            0.625    1.21875            0.4              0.762701  0.78                        0.828503            0.0625          0.4875                     -37.5    21.875\n",
       "    11       0.5                         0.707086           1.25     1.225              0.8              0.727627  0.784                       0.808328            0.125           0.6125                     25       22.5\n",
       "    12       0.6                         0.653791           1        1.1875             0.64             0.679511  0.76                        0.786859            0.1             0.7125                     0        18.75\n",
       "    13       0.7                         0.582921           1.125    1.17857            0.72             0.617636  0.754286                    0.762684            0.1125          0.825                      12.5     17.8571\n",
       "    14       0.8                         0.512987           0.5      1.09375            0.32             0.549582  0.7                         0.736046            0.05            0.875                      -50      9.375\n",
       "    15       0.9                         0.383776           0.875    1.06944            0.56             0.446405  0.684444                    0.703864            0.0875          0.9625                     -12.5    6.94444\n",
       "    16       1                           0.180104           0.375    1                  0.24             0.297761  0.64                        0.663253            0.0375          1                          -62.5    0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.744</td>\n",
       "<td>0.0516914</td>\n",
       "<td>0.78</td>\n",
       "<td>0.86</td>\n",
       "<td>0.72</td>\n",
       "<td>0.64</td>\n",
       "<td>0.72</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.7491097</td>\n",
       "<td>0.0656146</td>\n",
       "<td>0.7149123</td>\n",
       "<td>0.9001782</td>\n",
       "<td>0.7552083</td>\n",
       "<td>0.6119162</td>\n",
       "<td>0.7633333</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.256</td>\n",
       "<td>0.0516914</td>\n",
       "<td>0.22</td>\n",
       "<td>0.14</td>\n",
       "<td>0.28</td>\n",
       "<td>0.36</td>\n",
       "<td>0.28</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>12.8</td>\n",
       "<td>2.5845697</td>\n",
       "<td>11.0</td>\n",
       "<td>7.0</td>\n",
       "<td>14.0</td>\n",
       "<td>18.0</td>\n",
       "<td>14.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.7719208</td>\n",
       "<td>0.0618707</td>\n",
       "<td>0.8119658</td>\n",
       "<td>0.9150327</td>\n",
       "<td>0.75</td>\n",
       "<td>0.6544502</td>\n",
       "<td>0.7281553</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.8238736</td>\n",
       "<td>0.0385793</td>\n",
       "<td>0.8735632</td>\n",
       "<td>0.8888889</td>\n",
       "<td>0.8108108</td>\n",
       "<td>0.7352941</td>\n",
       "<td>0.8108108</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.8890769</td>\n",
       "<td>0.0264396</td>\n",
       "<td>0.9452736</td>\n",
       "<td>0.8641975</td>\n",
       "<td>0.8823530</td>\n",
       "<td>0.8389262</td>\n",
       "<td>0.9146342</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>1.5823919</td>\n",
       "<td>0.1247817</td>\n",
       "<td>1.3157895</td>\n",
       "<td>1.5151515</td>\n",
       "<td>1.5625</td>\n",
       "<td>1.8518518</td>\n",
       "<td>1.6666666</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.588407</td>\n",
       "<td>0.0481179</td>\n",
       "<td>0.5582744</td>\n",
       "<td>0.5231090</td>\n",
       "<td>0.5649815</td>\n",
       "<td>0.7198398</td>\n",
       "<td>0.5758302</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.6261001</td>\n",
       "<td>0.1793332</td>\n",
       "<td>0.9166667</td>\n",
       "<td>0.1515152</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.6956522</td>\n",
       "<td>0.7</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.4133005</td>\n",
       "<td>0.1137864</td>\n",
       "<td>0.2542161</td>\n",
       "<td>0.7066865</td>\n",
       "<td>0.3546041</td>\n",
       "<td>0.2987288</td>\n",
       "<td>0.4522670</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.6615278</td>\n",
       "<td>0.0767496</td>\n",
       "<td>0.5416667</td>\n",
       "<td>0.8654189</td>\n",
       "<td>0.6354167</td>\n",
       "<td>0.6151369</td>\n",
       "<td>0.65</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.3384722</td>\n",
       "<td>0.0767496</td>\n",
       "<td>0.4583333</td>\n",
       "<td>0.1345811</td>\n",
       "<td>0.3645833</td>\n",
       "<td>0.3848631</td>\n",
       "<td>0.35</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.2020821</td>\n",
       "<td>0.0204141</td>\n",
       "<td>0.1901585</td>\n",
       "<td>0.1713665</td>\n",
       "<td>0.1940178</td>\n",
       "<td>0.2568556</td>\n",
       "<td>0.198012</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.7429407</td>\n",
       "<td>0.0772045</td>\n",
       "<td>0.7755102</td>\n",
       "<td>0.9333333</td>\n",
       "<td>0.7142857</td>\n",
       "<td>0.6097561</td>\n",
       "<td>0.6818182</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.0985236</td>\n",
       "<td>0.0811359</td>\n",
       "<td>-0.0425354</td>\n",
       "<td>0.2363349</td>\n",
       "<td>0.1579087</td>\n",
       "<td>-0.0340403</td>\n",
       "<td>0.1749500</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.9423822</td>\n",
       "<td>0.0396875</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8484849</td>\n",
       "<td>0.9375</td>\n",
       "<td>0.9259259</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.4484610</td>\n",
       "<td>0.0219634</td>\n",
       "<td>0.4360716</td>\n",
       "<td>0.4139643</td>\n",
       "<td>0.4404746</td>\n",
       "<td>0.5068092</td>\n",
       "<td>0.4449854</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.3806735</td>\n",
       "<td>0.1883264</td>\n",
       "<td>0.0833333</td>\n",
       "<td>0.8823530</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.3043478</td>\n",
       "<td>0.3</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean       sd         cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  ---------  ---------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.744      0.0516914  0.78          0.86          0.72          0.64          0.72\n",
       "auc                      0.74911    0.0656146  0.714912      0.900178      0.755208      0.611916      0.763333\n",
       "err                      0.256      0.0516914  0.22          0.14          0.28          0.36          0.28\n",
       "err_count                12.8       2.58457    11            7             14            18            14\n",
       "f0point5                 0.771921   0.0618707  0.811966      0.915033      0.75          0.65445       0.728155\n",
       "f1                       0.823874   0.0385793  0.873563      0.888889      0.810811      0.735294      0.810811\n",
       "f2                       0.889077   0.0264396  0.945274      0.864198      0.882353      0.838926      0.914634\n",
       "lift_top_group           1.58239    0.124782   1.31579       1.51515       1.5625        1.85185       1.66667\n",
       "logloss                  0.588407   0.0481179  0.558274      0.523109      0.564981      0.71984       0.57583\n",
       "max_per_class_error      0.6261     0.179333   0.916667      0.151515      0.666667      0.695652      0.7\n",
       "mcc                      0.413301   0.113786   0.254216      0.706686      0.354604      0.298729      0.452267\n",
       "mean_per_class_accuracy  0.661528   0.0767496  0.541667      0.865419      0.635417      0.615137      0.65\n",
       "mean_per_class_error     0.338472   0.0767496  0.458333      0.134581      0.364583      0.384863      0.35\n",
       "mse                      0.202082   0.0204141  0.190158      0.171366      0.194018      0.256856      0.198012\n",
       "precision                0.742941   0.0772045  0.77551       0.933333      0.714286      0.609756      0.681818\n",
       "r2                       0.0985236  0.0811359  -0.0425354    0.236335      0.157909      -0.0340403    0.17495\n",
       "recall                   0.942382   0.0396875  1             0.848485      0.9375        0.925926      1\n",
       "rmse                     0.448461   0.0219634  0.436072      0.413964      0.440475      0.506809      0.444985\n",
       "specificity              0.380673   0.188326   0.0833333     0.882353      0.333333      0.304348      0.3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_pr_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-07-25 05:31:46</td>\n",
       "<td>24.093 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5</td>\n",
       "<td>0.6931472</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.36</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-07-25 05:31:46</td>\n",
       "<td>24.168 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.4438398</td>\n",
       "<td>0.5862145</td>\n",
       "<td>0.9821528</td>\n",
       "<td>0.9783660</td>\n",
       "<td>1.5625</td>\n",
       "<td>0.068</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-07-25 05:31:46</td>\n",
       "<td>24.241 sec</td>\n",
       "<td>10.0</td>\n",
       "<td>0.3955226</td>\n",
       "<td>0.5013486</td>\n",
       "<td>0.9945139</td>\n",
       "<td>0.9907866</td>\n",
       "<td>1.5625</td>\n",
       "<td>0.04</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-07-25 05:31:46</td>\n",
       "<td>24.306 sec</td>\n",
       "<td>15.0</td>\n",
       "<td>0.3568671</td>\n",
       "<td>0.4372784</td>\n",
       "<td>0.9985417</td>\n",
       "<td>0.9929776</td>\n",
       "<td>1.5625</td>\n",
       "<td>0.012</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-07-25 05:31:46</td>\n",
       "<td>24.354 sec</td>\n",
       "<td>20.0</td>\n",
       "<td>0.3230448</td>\n",
       "<td>0.3841441</td>\n",
       "<td>0.9997917</td>\n",
       "<td>0.9936346</td>\n",
       "<td>1.5625</td>\n",
       "<td>0.004</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-07-25 05:31:46</td>\n",
       "<td>24.394 sec</td>\n",
       "<td>25.0</td>\n",
       "<td>0.2948525</td>\n",
       "<td>0.3419081</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9937500</td>\n",
       "<td>1.5625</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-07-25 05:31:47</td>\n",
       "<td>24.431 sec</td>\n",
       "<td>30.0</td>\n",
       "<td>0.2698593</td>\n",
       "<td>0.3056458</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9937500</td>\n",
       "<td>1.5625</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-07-25 05:31:47</td>\n",
       "<td>24.467 sec</td>\n",
       "<td>35.0</td>\n",
       "<td>0.2481505</td>\n",
       "<td>0.2752100</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9937500</td>\n",
       "<td>1.5625</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-07-25 05:31:47</td>\n",
       "<td>24.502 sec</td>\n",
       "<td>40.0</td>\n",
       "<td>0.2278577</td>\n",
       "<td>0.2478314</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9937500</td>\n",
       "<td>1.5625</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-07-25 05:31:47</td>\n",
       "<td>24.538 sec</td>\n",
       "<td>45.0</td>\n",
       "<td>0.2102973</td>\n",
       "<td>0.2248279</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9937500</td>\n",
       "<td>1.5625</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-07-25 05:31:47</td>\n",
       "<td>24.576 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.1963345</td>\n",
       "<td>0.2060871</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9937500</td>\n",
       "<td>1.5625</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-07-25 05:31:47</td>\n",
       "<td>24.613 sec</td>\n",
       "<td>55.0</td>\n",
       "<td>0.1865572</td>\n",
       "<td>0.1940411</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9937500</td>\n",
       "<td>1.5625</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-07-25 05:31:47</td>\n",
       "<td>24.648 sec</td>\n",
       "<td>60.0</td>\n",
       "<td>0.1711815</td>\n",
       "<td>0.1754964</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9937500</td>\n",
       "<td>1.5625</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-07-25 05:31:47</td>\n",
       "<td>24.681 sec</td>\n",
       "<td>64.0</td>\n",
       "<td>0.1634184</td>\n",
       "<td>0.1665258</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9937500</td>\n",
       "<td>1.5625</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error\n",
       "--  -------------------  ----------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------\n",
       "    2019-07-25 05:31:46  24.093 sec  0                  0.5              0.693147            0.5             0                  1                0.36\n",
       "    2019-07-25 05:31:46  24.168 sec  5                  0.44384          0.586214            0.982153        0.978366           1.5625           0.068\n",
       "    2019-07-25 05:31:46  24.241 sec  10                 0.395523         0.501349            0.994514        0.990787           1.5625           0.04\n",
       "    2019-07-25 05:31:46  24.306 sec  15                 0.356867         0.437278            0.998542        0.992978           1.5625           0.012\n",
       "    2019-07-25 05:31:46  24.354 sec  20                 0.323045         0.384144            0.999792        0.993635           1.5625           0.004\n",
       "    2019-07-25 05:31:46  24.394 sec  25                 0.294852         0.341908            1               0.99375            1.5625           0\n",
       "    2019-07-25 05:31:47  24.431 sec  30                 0.269859         0.305646            1               0.99375            1.5625           0\n",
       "    2019-07-25 05:31:47  24.467 sec  35                 0.24815          0.27521             1               0.99375            1.5625           0\n",
       "    2019-07-25 05:31:47  24.502 sec  40                 0.227858         0.247831            1               0.99375            1.5625           0\n",
       "    2019-07-25 05:31:47  24.538 sec  45                 0.210297         0.224828            1               0.99375            1.5625           0\n",
       "    2019-07-25 05:31:47  24.576 sec  50                 0.196335         0.206087            1               0.99375            1.5625           0\n",
       "    2019-07-25 05:31:47  24.613 sec  55                 0.186557         0.194041            1               0.99375            1.5625           0\n",
       "    2019-07-25 05:31:47  24.648 sec  60                 0.171182         0.175496            1               0.99375            1.5625           0\n",
       "    2019-07-25 05:31:47  24.681 sec  64                 0.163418         0.166526            1               0.99375            1.5625           0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>33</td>\n",
       "<td>339.1589661</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1409011</td></tr>\n",
       "<tr><td>65</td>\n",
       "<td>140.3394775</td>\n",
       "<td>0.4137867</td>\n",
       "<td>0.0583030</td></tr>\n",
       "<tr><td>217</td>\n",
       "<td>120.4042130</td>\n",
       "<td>0.3550082</td>\n",
       "<td>0.0500211</td></tr>\n",
       "<tr><td>117</td>\n",
       "<td>119.1591034</td>\n",
       "<td>0.3513370</td>\n",
       "<td>0.0495038</td></tr>\n",
       "<tr><td>91</td>\n",
       "<td>80.4987640</td>\n",
       "<td>0.2373482</td>\n",
       "<td>0.0334426</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>233</td>\n",
       "<td>0.6396351</td>\n",
       "<td>0.0018859</td>\n",
       "<td>0.0002657</td></tr>\n",
       "<tr><td>87</td>\n",
       "<td>0.4564552</td>\n",
       "<td>0.0013458</td>\n",
       "<td>0.0001896</td></tr>\n",
       "<tr><td>218</td>\n",
       "<td>0.2399101</td>\n",
       "<td>0.0007074</td>\n",
       "<td>0.0000997</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.1210165</td>\n",
       "<td>0.0003568</td>\n",
       "<td>0.0000503</td></tr>\n",
       "<tr><td>181</td>\n",
       "<td>0.0340252</td>\n",
       "<td>0.0001003</td>\n",
       "<td>0.0000141</td></tr></table></div>"
      ],
      "text/plain": [
       "variable    relative_importance    scaled_importance       percentage\n",
       "----------  ---------------------  ----------------------  ----------------------\n",
       "33          339.1589660644531      1.0                     0.1409011439735031\n",
       "65          140.3394775390625      0.4137867241651888      0.05830302279592348\n",
       "217         120.40421295166016     0.3550081967427002      0.05002106104101691\n",
       "117         119.15910339355469     0.3513370286985423      0.049503789263876094\n",
       "91          80.49876403808594      0.23734818209932892     0.03344263037782677\n",
       "---         ---                    ---                     ---\n",
       "233         0.6396350860595703     0.0018859447930325843   0.0002657317788091627\n",
       "87          0.4564552307128906     0.0013458445047451488   0.00018963103032904418\n",
       "218         0.23991012573242188    0.0007073677824776415   9.966892976109978e-05\n",
       "1           0.1210165023803711     0.00035681351368836684  5.0275432263896094e-05\n",
       "181         0.03402519226074219    0.00010032225494600695  1.4135520487893809e-05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost prediction progress: |████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "preds = aml.predict(test_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = preds['p1'].as_data_frame().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "3f9eaa7e7996db537b4c31ab5ffaa2ac6c9d9aa3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19750, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm = pd.read_csv('../input/sample_submission.csv')\n",
    "subm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "adc8243b5bde5e0096e49641699214fbaa2000e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19750, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "130ab5dc4e26198892cfa61103685d49996ad763"
   },
   "outputs": [],
   "source": [
    "subm['target'] = y_pred\n",
    "subm.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "449f090ec6520ecb8936523c8e61d7a4cbfc5edf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
